train: True
batch_size: 128
epochs: 20
eval_every_n_epochs: 2
log_every_n_steps: 200
learning_rate: 4e-4
weight_decay: 1e-6
fp16_precision: True
truncation: True
dset: primitives
CLIP: False

model:
  out_dim: 512
  res_base_model: "resnet50"
  bert_base_model: "BiGRU"
  # bert_base_model: "bert-base-uncased"
  freeze_layers: #[0,1,2,3,4,5]
  do_lower_case: False
  sparse_model: False
  use_voxel: False
  tri_modal: True
  num_images: 6
  image_cnn: 'resnet18'
  pretraining: True

dataset:
  s: 1
  input_shape: (64,64,64,4)
  num_workers: 4
  train_json_file: 'datasets/text2shape-data/primitives/train_map.jsonl'
  val_json_file: 'datasets/text2shape-data/primitives/val_map.jsonl'
  test_json_file: 'datasets/text2shape-data/primitives/test_map.jsonl'
  voxel_root_dir: 'datasets/text2shape-data/primitives/primitives'
  transform: 0 # the probability to do data augmentation, 0: no augmentation

loss:
  temperature: 0.1
  use_cosine_similarity: True
  alpha_weight: 0.25

# train: False
# batch_size: 32
# epochs: 5
# eval_every_n_epochs: 2
# fine_tune_from: Sep01_04-11-50_cs-3dlg-01 
# log_every_n_steps: 200
# learning_rate: 1e-4
# weight_decay: 1e-6
# fp16_precision: True
# truncation: True
# config_file: tricolo/configs/retrieval_primitives.yaml
# dset: primitives

# model:
#   out_dim: 512
#   res_base_model: "resnet50"
#   bert_base_model: 'bert-base-uncased'
#   freeze_layers: [0,1,2,3,4,5]
#   do_lower_case: False
  
# dataset:
#   s: 1
#   input_shape: (64,64,64,4)
#   num_workers: 4 #4
#   train_json_file: '../data/retrieval/primitives/train_map.jsonl'
#   val_json_file: '../data/retrieval/primitives/val_map.jsonl'
#   test_json_file: '../data/retrieval/primitives/test_map.jsonl'
#   voxel_root_dir: '../data/retrieval/primitives/mat_64_filter_div_32_solid'
#   transform: 0 # the probability to do data augmentation, 0: no augmentation

# loss:
#   temperature: 0.1
#   use_cosine_similarity: True
#   alpha_weight: 0.25
